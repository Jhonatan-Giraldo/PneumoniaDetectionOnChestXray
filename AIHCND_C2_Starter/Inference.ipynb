{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function reads in a .dcm file, checks the important fields for our device, and returns a numpy array\n",
    "# of just the imaging data\n",
    "def check_dicom(filename): \n",
    "    # todo\n",
    "    \n",
    "    print('Load file {} ...'.format(filename))\n",
    "    ds = pydicom.dcmread(filename)       \n",
    "    img = ds.pixel_array\n",
    "    img_mean = np.mean(img)\n",
    "    img_std = np.std(img)\n",
    "    return (img, img_mean, img_std)\n",
    "    \n",
    "    \n",
    "# This function takes the numpy array output by check_dicom and \n",
    "# runs the appropriate pre-processing needed for our model input\n",
    "def preprocess_image(img,img_mean,img_std,img_size): \n",
    "    # todo\n",
    "    # resize the image\n",
    "    img = resize(img, img_size)\n",
    "\n",
    "    # standardize the image pixel values.\n",
    "    proc_img = (img - img_mean)/img_std\n",
    "    return proc_img\n",
    "\n",
    "# This function loads in our trained model w/ weights and compiles it \n",
    "def load_model(model_path, weight_path):\n",
    "    # todo\n",
    "    json_file = open(model_path, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = keras.models.model_from_json(loaded_model_json)\n",
    "    model.load_weights(weight_path)\n",
    "    model.compile(optimizer = Adam(lr=1e-4), loss = 'binary_crossentropy', metrics = ['binary_accuracy'])\n",
    "    return model\n",
    "\n",
    "# This function uses our device's threshold parameters to predict whether or not\n",
    "# the image shows the presence of pneumonia using our trained model\n",
    "def predict_image(model, img, thresh): \n",
    "    # todo  \n",
    "    prediction  = model.predict(img)\n",
    "    if(prediction >=thresh):\n",
    "        prediction = 1.0\n",
    "    else:\n",
    "        prediction = 0.0\n",
    "    \n",
    "    return prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcbe0237f50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skimage.transform import resize\n",
    "x= pydicom.dcmread('test1.dcm')\n",
    "img = x.pixel_array \n",
    "img = resize(img, (1,224,224,3))\n",
    "print(img.shape)\n",
    "plt.imshow(img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load file test1.dcm ...\n",
      "0.0\n",
      "Load file test2.dcm ...\n",
      "0.0\n",
      "Load file test3.dcm ...\n",
      "0.0\n",
      "Load file test4.dcm ...\n",
      "0.0\n",
      "Load file test5.dcm ...\n",
      "0.0\n",
      "Load file test6.dcm ...\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "test_dicoms = ['test1.dcm','test2.dcm','test3.dcm','test4.dcm','test5.dcm','test6.dcm']\n",
    "\n",
    "model_path = 'my_model.json'\n",
    "weight_path = 'xray_class_my_model.best.hdf5'\n",
    "\n",
    "IMG_SIZE=(1,224,224,3) # This might be different if you did not use vgg16\n",
    "# img_mean = # loads the mean image value they used during training preprocessing\n",
    "# img_std = # loads the std dev image value they used during training preprocessing\n",
    "\n",
    "my_model = load_model(model_path, weight_path)\n",
    "thresh = 0.7144732 #loads the threshold they chose for model classification \n",
    "\n",
    "# use the .dcm files to test your prediction\n",
    "for i in test_dicoms:\n",
    "    \n",
    "    img = np.array([])\n",
    "    img, img_mean, img_std = check_dicom(i)\n",
    "    \n",
    "    if img is None:\n",
    "        continue\n",
    "        \n",
    "    img_proc = preprocess_image(img,img_mean,img_std,IMG_SIZE)\n",
    "    pred = predict_image(my_model,img_proc,thresh)\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some analytics on dicom metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0008, 0016) SOP Class UID                       UI: Secondary Capture Image Storage\n",
       "(0008, 0018) SOP Instance UID                    UI: 1.3.6.1.4.1.11129.5.5.110503645592756492463169821050252582267888\n",
       "(0008, 0060) Modality                            CS: 'DX'\n",
       "(0008, 1030) Study Description                   LO: 'No Finding'\n",
       "(0010, 0020) Patient ID                          LO: '2'\n",
       "(0010, 0040) Patient's Sex                       CS: 'M'\n",
       "(0010, 1010) Patient's Age                       AS: '81'\n",
       "(0018, 0015) Body Part Examined                  CS: 'CHEST'\n",
       "(0018, 5100) Patient Position                    CS: 'PA'\n",
       "(0020, 000d) Study Instance UID                  UI: 1.3.6.1.4.1.11129.5.5.112507010803284478207522016832191866964708\n",
       "(0020, 000e) Series Instance UID                 UI: 1.3.6.1.4.1.11129.5.5.112630850362182468372440828755218293352329\n",
       "(0028, 0002) Samples per Pixel                   US: 1\n",
       "(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n",
       "(0028, 0010) Rows                                US: 1024\n",
       "(0028, 0011) Columns                             US: 1024\n",
       "(0028, 0100) Bits Allocated                      US: 8\n",
       "(0028, 0101) Bits Stored                         US: 8\n",
       "(0028, 0102) High Bit                            US: 7\n",
       "(0028, 0103) Pixel Representation                US: 0\n",
       "(7fe0, 0010) Pixel Data                          OW: Array of 1048576 elements"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at all the info in a dicom file.\n",
    "x = pydicom.dcmread(test_dicoms[0])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', 81, 'M', 'DX', 'No Finding', 'CHEST', 1024, 1024]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = []\n",
    "for each in test_dicoms:\n",
    "    dcm = pydicom.dcmread(each)\n",
    "    fields = [dcm.PatientID, int(dcm.PatientAge), dcm.PatientSex, dcm.Modality, dcm.StudyDescription, dcm.BodyPartExamined,\n",
    "              dcm.Rows, dcm.Columns]\n",
    "    metadata.append(fields)\n",
    "metadata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>PatientAge</th>\n",
       "      <th>PatientSex</th>\n",
       "      <th>Modality</th>\n",
       "      <th>Findings</th>\n",
       "      <th>BPE</th>\n",
       "      <th>Rows</th>\n",
       "      <th>Columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>M</td>\n",
       "      <td>DX</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>CHEST</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>DX</td>\n",
       "      <td>Cardiomegaly</td>\n",
       "      <td>CHEST</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61</td>\n",
       "      <td>77</td>\n",
       "      <td>M</td>\n",
       "      <td>DX</td>\n",
       "      <td>Effusion</td>\n",
       "      <td>CHEST</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>M</td>\n",
       "      <td>DX</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>RIBCAGE</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>M</td>\n",
       "      <td>CT</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>CHEST</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>M</td>\n",
       "      <td>DX</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>CHEST</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PatientID  PatientAge PatientSex Modality      Findings      BPE  Rows  \\\n",
       "0         2          81          M       DX    No Finding    CHEST  1024   \n",
       "1         1          58          M       DX  Cardiomegaly    CHEST  1024   \n",
       "2        61          77          M       DX      Effusion    CHEST  1024   \n",
       "3         2          81          M       DX    No Finding  RIBCAGE  1024   \n",
       "4         2          81          M       CT    No Finding    CHEST  1024   \n",
       "5         2          81          M       DX    No Finding    CHEST  1024   \n",
       "\n",
       "   Columns  \n",
       "0     1024  \n",
       "1     1024  \n",
       "2     1024  \n",
       "3     1024  \n",
       "4     1024  \n",
       "5     1024  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadf = pd.DataFrame(metadata, \n",
    "                      columns = ['PatientID','PatientAge','PatientSex','Modality','Findings','BPE','Rows','Columns'])\n",
    "metadf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the images have Pneumonia as finding(classified by radiologists). Modality of all the images is DX(Digital Radiography). 3 patients all together as patient with ID 2 is tested repetedly. The Body part examined in all the X-rays is Chest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
